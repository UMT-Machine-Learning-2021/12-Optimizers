{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic gradient descent\n",
    "\n",
    "## 1 Linear model gradients\n",
    "In the last section, you may have noticed that we did something a little bit different than normal gradient descent to optimize the models that created in PyTorch.  The most dramatic change was that we loaded our training data in *batches*, which is to say that we only looked at a subset of all the data at one time.  This is a method called mini-batch gradient descent, and this notebook discusses why we do this and why it works.  To start with, let's look at the specific case of mini-batch gradient descent where we look at exactly one data point per step of gradient descent, which is called *stochastic gradient descent*.\n",
    "\n",
    "Stochastic gradient descent is a useful technique when it would be prohibitively expensive to run all of the training examples at once, or when we wish to update our model in a sequential way.  Here we demonstrate the difference in the convergence properties of batch versus stochastic gradient descent for the simple problem of linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (9,9)\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a dataset generated from a line with noised added:\n",
    "$$ y = x + 1 + \\epsilon $$\n",
    "$$ x \\in [0,1]. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create constantly-spaced x-values\n",
    "x = np.linspace(0,1,21)\n",
    "\n",
    "# Create a linear function of $x$ with slope 1, intercept 1, and normally distributed error with sd=1\n",
    "y = x + np.random.randn(len(x))*0.1 + 1.0\n",
    "plt.plot(x,y,'k.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize our weights to zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an initial guess for the weights\n",
    "w = np.array([0.,0.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our cost function (or alternatively negative log-likelihood) is simple least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cost function (sum square error between prediction and data points)\n",
    "def L(w,x,y):\n",
    "    return 1./2.*sum((y - w[0] - w[1]*x)**2)\n",
    "\n",
    "# Evaluate the cost function at many values of slope and intercept, aka the brute force method.  \n",
    "# To be used for visualization purposes\n",
    "L_grid = np.zeros((101,101))\n",
    "w0s = np.linspace(0,1.5,101)\n",
    "w1s = np.linspace(0,1,101)\n",
    "for i,w1 in enumerate(w1s):\n",
    "    for j,w0 in enumerate(w0s):\n",
    "        L_grid[i,j] = L([w0,w1],x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that to solve the least squares problem, we take the derivative of this thing with respect to the weights, set them equal to zero.  This produces the normal equations:\n",
    "$$\n",
    "\\Phi^T \\Phi W = \\Phi^T y\n",
    "$$\n",
    "which have an analytical solution.  However, for the purposes of illustration, we can assume that we can't just solve them, and have to use gradient descent.  The gradient for the intercept and the slope of the line we want to fit are \n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_0} = -\\sum_{i=1}^m (y_i - w_0 - w_1 x_i)\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_1} = -\\sum_{i=1}^m (y_i - w_0 - w_1 x_i) x_i\n",
    "$$\n",
    "Writing a python function for this gives us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient function\n",
    "def G(w,x,y):\n",
    "    return np.array([-sum(y - w[0] - w[1]*x),-sum((y - w[0] - w[1]*x)*x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Batch Gradient Descent\n",
    "\n",
    "First, we can run so-called batch gradient descent, in which we compute the objective function considering **all the data points at once**.  We'll save our weights at each epoch, so that we can plot them.  A learning rate $\\eta=0.01$ works well for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to hold our weight values at each step of gradient descent\n",
    "w_batch = [w.copy()]\n",
    "\n",
    "# Set the learning rate\n",
    "eta = 0.01\n",
    "\n",
    "# Loop over the data 10000 times\n",
    "for i in range(10000):\n",
    "    \n",
    "    # Update the weights by taking a small step in the negative direction of the gradient\n",
    "    w -= eta*G(w,x,y)\n",
    "    \n",
    "    # Append the new parameters to our list of weights\n",
    "    w_batch.append(w.copy())\n",
    "    \n",
    "# Convert the list to a numpy array\n",
    "w_batch = np.array(w_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our path to the minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a contour plot of the grid of cost-function values\n",
    "plt.contour(w0s,w1s,L_grid,20)\n",
    "\n",
    "# Plot the weight values on our way toward the cost-function minimum\n",
    "plt.plot(w_batch[:,0],w_batch[:,1],'go-')\n",
    "plt.xlabel('Intercept')\n",
    "plt.ylabel('Slope')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Stochastic gradient descent\n",
    "It's not always possible to fit all the data in memory, and so we have to do something different.  One simple thing that we can do is to compute the gradient of the objective function considering only *one datapoint at a time*, sampled at random without replacement from the dataset.  We'll save both the weight values at these individual steps, and also the weights at the end of each *epoch*, which is what we call the outer iteration in which we look at each data point once; in batch gradient descent, we look at all the data at once, so an epoch corresponds to one iteration of BGD.  In stochastic gradient descent, we'll take $m$ steps of gradient descent per epoch.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "w = np.array([0.,0.])\n",
    "\n",
    "# Initialize arrays to hold weights\n",
    "w_stoch = [w.copy()]\n",
    "w_epoch = [w.copy()]\n",
    "\n",
    "# Define learning rates\n",
    "eta = 0.01\n",
    "\n",
    "# Train for 10000 epochs\n",
    "for i in range(10000):\n",
    "    \n",
    "    # Draw random indices of the dataset\n",
    "    random_indices = np.random.choice(range(len(x)),len(x),replace=False)\n",
    "    \n",
    "    # Loop over all of the data points without replacement\n",
    "    for j in random_indices:\n",
    "        \n",
    "        # Take as a sample the j-th element in the training data\n",
    "        x_sample = x[j]\n",
    "        y_sample = y[j]\n",
    "        \n",
    "        # Take a gradient descent step based on that single data point\n",
    "        w -= eta*G(w,np.array([x_sample]),np.array([y_sample]))\n",
    "        w_stoch.append(w.copy())\n",
    "    \n",
    "    # Store the weights at the end of the epoch\n",
    "    w_epoch.append(w.copy())\n",
    "\n",
    "# Convert lists to arrays\n",
    "w_stoch = np.array(w_stoch)\n",
    "w_epoch = np.array(w_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this on top of the results from batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the error surface\n",
    "plt.contour(w0s,w1s,L_grid,20)\n",
    "\n",
    "# Plot the results of batch gradient descent in green\n",
    "plt.plot(w_batch[:,0],w_batch[:,1],'go-')\n",
    "\n",
    "# Plot the results of stochastic gradient descent in blue\n",
    "plt.plot(w_stoch[:,0],w_stoch[:,1],'b-')\n",
    "plt.plot(w_epoch[:,0],w_epoch[:,1],'bo')\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.xlabel('Intercept')\n",
    "plt.ylabel('Slope')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some wiggles, but the stochastic value after each epoch falls remarkably close to the batch descent line.  This is even more interesting if we zoom in on the upper right region (near convergence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(w_batch[:,0],w_batch[:,1],'go-')\n",
    "plt.plot(w_stoch[:,0],w_stoch[:,1],'b-')\n",
    "plt.plot(w_epoch[:,0],w_epoch[:,1],'bo')\n",
    "\n",
    "plt.xlim(1.1,1.2)\n",
    "plt.ylim(0.7,0.8)\n",
    "\n",
    "plt.xlabel('Intercept')\n",
    "plt.ylabel('Slope')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does this work?  Let's look at the sum of the individual weight updates in SGD over an epoch.  An update based on a single data point would be:\n",
    "$$\n",
    "\\Delta w_{i} = \\eta [y_i - w_{0,i} - w_{1,i} x_i, (y_i - w_{0,i} - w_{1,i}) x_i].\n",
    "$$\n",
    "What does the update after an entire epoch (i.e. a complete loop through the data) look like.  That would just be the sum over all $m$ updates in the \"inner\" loop, with the constant step size moved outside the sum (summation is linear after all):\n",
    "$$\n",
    "\\Delta w_{SGD} = \\eta [\\sum_{i=1}^m (y_i - w_{0,i} - w_{1,i} x_i),\\sum_{i=1}^m (y_i - w_{0,i} - w_{1,i} x_i)x_i]\n",
    "$$\n",
    "Compare this to the update for batch gradient descent\n",
    "$$\n",
    "\\Delta w_{BGD} = \\eta [\\sum_{i=1}^m (y_i - w_{0} - w_{1} x_i),\\sum_{i=1}^m (y_i - w_{0} - w_{1} x_i)x_i]\n",
    "$$\n",
    "You'll note that it's exactly the same, with the exception of the subscripts on the weights.  However, since the weights aren't changing very rapidly (we're taking small steps after all), the resulting updates are very close to identical: all the little steps taken in SGD average out to produce something quite close to batch gradient descent.\n",
    "\n",
    "## In Class: Implement mini-batch gradient descent for linear regression\n",
    "These are two end-member options for dealing with gradient descent.  The best solution for the purposes of machine learning lies somewhere in the middle, via a technique called mini-batch gradient descent.  In mini-batch gradient descent, at each epoch we split the data-set into $k$ subsets of a specified size known as the *batch size*, and take $k$ steps based on the objective function gradient considering only the $m/k$ data points in a given mini-batch.  \n",
    "\n",
    "Using the code given above as a starting point, implement mini-batch gradient descent.  You will have to generate methods that A) create random disjoint subsets of the training data of the size $m/k$, and B) update the weights $k$ times per epoch.  Plot the results of mini-batch gradient descent along with batch and stochastic gradient descents from above, using the same initial guess for $\\mathbf{w}$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should expect the mini-batch gradient descent produces results which are somewhat intermediate between the stochastic and batch versions.  \n",
    "\n",
    "It's worth noting that for this example, stochastic gradient descent takes quite a bit more time to run.  This is because our dataset is relatively small, and the problem we are trying to solve is relatively simple.  However, in large scale problems (think running neural networks over millions of images), it's not possible to fit the training set into memory, and the computation becomes overwhelming.  Simultaneously, in cases where there are many local minimina, SGD may perform better because some local minima may only form for a large number of data points simultaneously.  In this sense, it may also be viewed as a form of *regularization*, because it helps the model avoid overfitting.\n",
    "\n",
    "### Momentum\n",
    "\n",
    "One popular variant on gradient descent is the inclusion of momentum.  Momentum utilizes the following parameter update:\n",
    "$$\n",
    "\\Delta \\mathbf{w}_i = m \\Delta \\mathbf{w}_{i-1} + (1-m) \\nabla \\mathbf{w}_i\n",
    "$$\n",
    "$$\n",
    "\\mathbf{w}_{i+1} = \\mathbf{w}_i - \\eta \\Delta \\mathbf{w}_i\n",
    "$$\n",
    "This effectively makes the update direction slower to change, and can help to push the model up and out of local minima.  Let's illustrate it's function using stochastic gradient descent (mini-batch size 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "w = np.array([0.,0.])\n",
    "\n",
    "# Initialize weight storage\n",
    "w_momen = [w.copy()]\n",
    "w_mepoch = [w.copy()]\n",
    "\n",
    "# Define learning rate\n",
    "eta = 0.01\n",
    "\n",
    "# Define momentum parameter\n",
    "momentum = 0.9\n",
    "\n",
    "# Define a variable to hold the update step from the previous time step\n",
    "delta_w = 0.0\n",
    "\n",
    "# Loop over 10000 epochs\n",
    "for i in range(10000):\n",
    "\n",
    "    # Shuffle the data points\n",
    "    random_indices = np.random.choice(range(len(x)),len(x),replace=False)\n",
    "    \n",
    "    # Loop over all the shuffled data points\n",
    "    for j in random_indices:\n",
    "        \n",
    "        # Draw the relevant data point from the big data array\n",
    "        x_sample = x[j]\n",
    "        y_sample = y[j]\n",
    "        \n",
    "        # Compute the update direction (no longer just the gradient: now a weighted average of the\n",
    "        # gradient with previous gradients)\n",
    "        delta_w = momentum*delta_w + (1.-momentum)*G(w,np.array([x_sample]),np.array([y_sample]))\n",
    "        \n",
    "        # Update weights\n",
    "        w -= eta*delta_w\n",
    "        \n",
    "        # Store weights\n",
    "        w_momen.append(w.copy())\n",
    "    \n",
    "    # Store epoch weights\n",
    "    w_mepoch.append(w.copy())\n",
    "\n",
    "# convert lists to arrays\n",
    "w_momen = np.array(w_momen)\n",
    "w_mepoch = np.array(w_mepoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error surface\n",
    "plt.contour(w0s,w1s,L_grid,20)\n",
    "\n",
    "#Plot batch gradient descent, SGD, and SGD w/ momentum\n",
    "plt.plot(w_batch[:,0],w_batch[:,1],'go-')\n",
    "plt.plot(w_stoch[:,0],w_stoch[:,1],'b-')\n",
    "plt.plot(w_momen[:,0],w_momen[:,1],'r-')\n",
    "plt.axis('equal')\n",
    "#plt.xlim(1.1,1.2)\n",
    "#plt.ylim(0.7,0.8)\n",
    "\n",
    "plt.xlabel('Intercept')\n",
    "plt.ylabel('Slope')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above but zoomed in\n",
    "\n",
    "plt.plot(w_batch[:,0],w_batch[:,1],'go-')\n",
    "plt.plot(w_stoch[:,0],w_stoch[:,1],'b-')\n",
    "plt.plot(w_momen[:,0],w_momen[:,1],'r-')\n",
    "\n",
    "plt.xlim(1.1,1.2)\n",
    "plt.ylim(0.7,0.8)\n",
    "\n",
    "plt.xlabel('Intercept')\n",
    "plt.ylabel('Slope')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum reduces the size of the wiggles due to the stochasticity in stochastic gradient descent.  \n",
    "\n",
    "### RMSprop\n",
    "One final popular variant of gradient descent is called RMSprop, and it is similar to gradient descent with momentum, but with a twist: instead of keeping a running average of the gradient, RMSprop keeps a running average of the squared gradient.  Then, when it comes time to update the weights, it normalizes the gradient by the square-root of this average-squared gradient. \n",
    "$$\n",
    "\\bar{g^2}_i = m \\bar{g^2}_{i-1} + (1-m) (\\nabla \\mathbf{w}_i)^2\n",
    "$$\n",
    "$$\n",
    "\\mathbf{w}_{i+1} = \\mathbf{w}_i - \\eta \\frac{\\nabla \\mathbf{w}_i}{\\sqrt{\\bar{g^2}}}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "What does this do?  It effectively eliminates the scale of the gradient from the problem, and we only go downhill based on the sign, which is very useful when the gradients of the different parameters are very different from one another.  The momentum is necessary because the sign of the gradient can jump around alot with SGD, so it's better to know *generally* which direction is down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "w = np.array([0.,0.])\n",
    "\n",
    "# Initialize storage\n",
    "w_momen = [w.copy()]\n",
    "w_mepoch = [w.copy()]\n",
    "\n",
    "# Set learning rate (Lower because this method learns really fast!)\n",
    "eta = 0.0001\n",
    "\n",
    "# Set momentum\n",
    "momentum = 0.9\n",
    "\n",
    "# Initialize average squared gradient\n",
    "g2 = 0\n",
    "\n",
    "# Iterate over 10000 epochs\n",
    "for i in range(10000):\n",
    "\n",
    "    # Randomly shuffle indices\n",
    "    random_indices = np.random.choice(range(len(x)),len(x),replace=False)\n",
    "    \n",
    "    # Loop over shuffled indices\n",
    "    for j in random_indices:\n",
    "        \n",
    "        # Extract single data point\n",
    "        x_sample = x[j]\n",
    "        y_sample = y[j]\n",
    "        \n",
    "        # Compute the gradient\n",
    "        gradient = G(w,np.array([x_sample]),np.array([y_sample]))\n",
    "        \n",
    "        # Update averaged square gradient\n",
    "        g2 = momentum*g2 + (1.-momentum)*gradient**2\n",
    "        \n",
    "        # Update with gradient normalized by root square average gradient\n",
    "        w -= eta*gradient/(np.sqrt(g2) + 1e-8)\n",
    "        \n",
    "        # Store weight values\n",
    "        w_momen.append(w.copy())\n",
    "    w_mepoch.append(w.copy())       \n",
    "w_momen = np.array(w_momen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contour(w0s,w1s,L_grid,20)\n",
    "plt.plot(w_batch[:,0],w_batch[:,1],'go-')\n",
    "plt.plot(w_stoch[:,0],w_stoch[:,1],'b-')\n",
    "plt.plot(w_momen[::1000,0],w_momen[::1000,1],'ro-')\n",
    "plt.axis('equal')\n",
    "#plt.xlim(1.1,1.2)\n",
    "#plt.ylim(0.7,0.8)\n",
    "\n",
    "plt.xlabel('Intercept')\n",
    "plt.ylabel('Slope')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(w_batch[:,0],w_batch[:,1],'go-')\n",
    "plt.plot(w_stoch[:,0],w_stoch[:,1],'b-')\n",
    "plt.plot(w_momen[:,0],w_momen[:,1],'r-')\n",
    "\n",
    "plt.xlim(1.1,1.2)\n",
    "plt.ylim(0.7,0.9)\n",
    "\n",
    "plt.xlabel('Intercept')\n",
    "plt.ylabel('Slope')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, RMSprop can be combined with normal momentum.  \n",
    "\n",
    "These are just a few examples of the large scale gradient descent schemes that can be used for general optimization problems, but especially neural networks.  There are many, many other methods (a good overview can be found [here](http://ruder.io/optimizing-gradient-descent/) ).  However, effectively, these are all just slight variations on the general theme of figuring out which way is down, and going that direction."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Class: \n",
    "Pytorch has all of these methods built in (and many more).  We'll explore some of them for MNIST, using the following code as a starting point.\n",
    "\n",
    "Model Specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        This method is where you'll want to instantiate parameters.\n",
    "        we do this by creating two linear transformation functions, l1 and l2, which \n",
    "        have encoded in it both the weight matrices W_1 and W_2, and the bias vectors\n",
    "        \"\"\"\n",
    "        super(Net,self).__init__()\n",
    "        self.l1 = nn.Linear(784,128) # Transform from input to hidden layer\n",
    "        self.l2 = nn.Linear(128,10)\n",
    "        \n",
    "   \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        This method runs the feedforward neural network.  It takes a tensor of size m x 784,\n",
    "        applies a linear transformation, applies a sigmoidal activation, applies the second linear transform \n",
    "        and outputs the logits.\n",
    "        \"\"\"\n",
    "        # Apply dropout to the input\n",
    "        a1 = self.l1(x)\n",
    "        z1 = torch.sigmoid(a1)\n",
    "        \n",
    "        # Apply dropout to the hidden layer\n",
    "        a2 = self.l2(z1)\n",
    "\n",
    "        return a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# In order to run this in class, we're going to reduce the dataset by a factor of 5\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, cache=True)\n",
    "X/=255.\n",
    "y = y.astype(int)\n",
    "X,X_test,y,y_test = train_test_split(X,y,test_size=10000)\n",
    "\n",
    "# Extract number of data points, and the height and width of the images for later reshaping\n",
    "m = X.shape[0]\n",
    "n = X.shape[1]\n",
    "\n",
    "h = 28\n",
    "w = 28\n",
    "\n",
    "N = 10\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y = torch.from_numpy(y)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "X = X.to(torch.float32)\n",
    "X_test = X_test.to(torch.float32)\n",
    "y = y.to(torch.long)\n",
    "y_test = y_test.to(torch.long)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X = X.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y = y.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "training_data = TensorDataset(X,y)\n",
    "test_data = TensorDataset(X_test,y_test)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_data,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "batch_size = 256\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-3)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "total_train = 0\n",
    "correct_train = 0\n",
    "# Loop over the data\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    # Loop over each subset of data\n",
    "    for d,t in train_loader:\n",
    "\n",
    "        # Zero out the optimizer's gradient buffer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Make a prediction based on the model\n",
    "        outputs = model(d)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs,t)      \n",
    "\n",
    "        # Use backpropagation to compute the derivative of the loss with respect to the parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Use the derivative information to update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        total_train += float(t.size(0))\n",
    "        correct_train += float((predicted==t).sum())\n",
    "        \n",
    "    model.eval()\n",
    "    # After each epoch, compute the test set accuracy\n",
    "    total=0.\n",
    "    correct=0.\n",
    "    # Loop over all the test examples and accumulate the number of correct results in each batch\n",
    "    for d,t in test_loader:\n",
    "        outputs = model(d)\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        total += float(t.size(0))\n",
    "        correct += float((predicted==t).sum())\n",
    "        \n",
    "    # Print the epoch, the training loss, and the test set accuracy.\n",
    "    print(epoch,loss.item(),100.*correct_train/total_train,100.*correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, I would like you to generate two plots.  \n",
    "\n",
    "First, train for 50 (or more) epochs using three different optimization methods (I would suggest trying SGD, RMSprop, and Adam, but you are free to use whatever you like.  Documentation and options are [here](https://pytorch.org/docs/stable/optim.html)).  Record the loss and/or accuracy at each epoch for each method, and plot them all together.  Identify which optimization method works best for this problem and discuss why you think so.  \n",
    "\n",
    "Second, using the best method that you identified above, experiment with at least three different minibatch sizes, and perform a similar analysis to that above.  Also note any  performance differences (in the sense of computational speed) between the different batch sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
